{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 213,
            "source": [
                "# Twitter dataset\n",
                "\n",
                "import pandas as pd\n",
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "import re\n",
                "import string\n",
                "\n",
                "\n",
                "df= pd.read_csv(\"/Users/sarwaridas/Downloads/trainingandtestdata/training.1600000.processed.noemoticon.csv\",encoding='latin-1',header=None)#,names=[\"label\",\"ID\",\"date\",\"query\",\"user\",\"text\"])\n",
                "#df.drop(['query','user','ID','date'],axis=1,inplace=True)   \n",
                "df.head()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   0           1                             2         3                4  \\\n",
                            "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
                            "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
                            "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
                            "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
                            "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
                            "\n",
                            "                                                   5  \n",
                            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
                            "1  is upset that he can't update his Facebook by ...  \n",
                            "2  @Kenichan I dived many times for the ball. Man...  \n",
                            "3    my whole body feels itchy and like its on fire   \n",
                            "4  @nationwideclass no, it's not behaving at all....  "
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>0</th>\n",
                            "      <th>1</th>\n",
                            "      <th>2</th>\n",
                            "      <th>3</th>\n",
                            "      <th>4</th>\n",
                            "      <th>5</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>1467810369</td>\n",
                            "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>_TheSpecialOne_</td>\n",
                            "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0</td>\n",
                            "      <td>1467810672</td>\n",
                            "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>scotthamilton</td>\n",
                            "      <td>is upset that he can't update his Facebook by ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0</td>\n",
                            "      <td>1467810917</td>\n",
                            "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>mattycus</td>\n",
                            "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0</td>\n",
                            "      <td>1467811184</td>\n",
                            "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>ElleCTF</td>\n",
                            "      <td>my whole body feels itchy and like its on fire</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0</td>\n",
                            "      <td>1467811193</td>\n",
                            "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>Karoli</td>\n",
                            "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 213
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 214,
            "source": [
                "df[0]=df[0].replace(to_replace=4,value=1)\n",
                "df[0].value_counts()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0    800000\n",
                            "1    800000\n",
                            "Name: 0, dtype: int64"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 214
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 215,
            "source": [
                "#df.sample(50000).to_csv(\"sentiment140-small.csv\", header=None, index=None)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 216,
            "source": [
                "df[0].unique()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "array([0, 1])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 216
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "source": [
                "df.columns= [\"label\",\"ID\",\"date\",\"query\",\"user\",\"text\"]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "source": [
                "#setting label values to 0 & 1\n",
                "# df['label']= df['label'].replace({4:1})\n",
                "# df.label.value_counts()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "source": [
                "# data_pos= df[df['label']==1] #splitting by pos & neg tweets\n",
                "# data_neg= df[df['label']==0]\n",
                "# data_pos= data_pos.iloc[:int(20000)] #taking 1/4th of data\n",
                "# data_neg= data_neg.iloc[:int(20000)]\n",
                "# data=pd.concat([data_pos,data_neg])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 220,
            "source": [
                "df.label.value_counts()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "0    800000\n",
                            "1    800000\n",
                            "Name: label, dtype: int64"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 220
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 221,
            "source": [
                "punc=string.punctuation\n",
                "def cleaning_punctuations(text):\n",
                "  translator=str.maketrans(\"\",\"\",punc)\n",
                "  return text.translate(translator)\n",
                "\n",
                "\n",
                "def pre_processing_01(tweet):\n",
                "  '''\n",
                "  Basic pre-processing to clean data:\n",
                "  1. Usernames\n",
                "  2. URLs\n",
                "  3. Special Characters\n",
                "  4. Multiple Spaces\n",
                "  5. Emails\n",
                "  6. Numbers\n",
                "  7. Single Chars\n",
                "  '''\n",
                "  tweet=tweet.str.lower()\n",
                "  tweet = tweet.apply(lambda x:re.sub('@[^\\s]+','',str(x))) # Remove Handles (aka usernames)\n",
                "  tweet = tweet.apply(lambda x:re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',str(x))) # Remove URLs\n",
                "  tweet= tweet.apply(lambda x:' '.join(re.findall(r'\\w+', str(x)))) #remove special chars\n",
                "  #tweet= tweet.apply(lambda x:cleaning_punctuations(x)) #remove punctuations\n",
                "  tweet = tweet.apply(lambda x:re.sub('@[^\\s]+','',str(x))) # Remove emails\n",
                "  tweet = tweet.apply(lambda x:re.sub('[0-9]+','',str(x))) # Remove numbers\n",
                "  #\n",
                "  # tweet= tweet.apply(lambda x:re.sub(r'\\s+', ' ', str(x), flags=re.I)) #replace multiple spaces with single space\n",
                "  tweet = tweet.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
                "  return tweet"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 222,
            "source": [
                "df['text']= pre_processing_01(df.text)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 227,
            "source": [
                "df.text.sample(20)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "572348            hate impatientd work would take long catch\n",
                            "1093714    woke withpretty bad headache cure mango kiwi p...\n",
                            "1433929                         realscould totally less hour\n",
                            "690856      amm fuckin tired hours straight naps gnite vegas\n",
                            "1023589                                   thank god itfriday\n",
                            "338254                               smell really really bad\n",
                            "194234                god dammitwant bright futurelike color\n",
                            "95127              poor computer barely get internet anymore\n",
                            "1406819                                                yaaay\n",
                            "1284897     listening music today would begreat day go beach\n",
                            "115491                                 get room needbig rest\n",
                            "681625                              hopes big teddy fad okay\n",
                            "902384     rockstar photographer shoot went great tonight...\n",
                            "955099           hilltop hoods great squashed pit lost voice\n",
                            "1351092    loading people messages whilelisten veronicas ...\n",
                            "181034                                        boss job scary\n",
                            "483688                   gotcoldswear god ifve got swine flu\n",
                            "404990                     stuck home thesis onsaturday nite\n",
                            "768084     remember ittransformers opening day side world...\n",
                            "136334                   annoyed sainsbugs online isnworking\n",
                            "Name: text, dtype: object"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 227
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "from nltk.tokenize import RegexpTokenizer\n",
                "\n",
                "stopwords_list=set(stopwords.words('english'))\n",
                "def cleaning_stopwords(text):\n",
                "    return \" \".join([word for word in str(text).split() if word not in stopwords_list])\n",
                "\n",
                "\n",
                "def pre_processing_02(data):\n",
                "    '''\n",
                "    1. Removing stopwords (using NLTK)\n",
                "    2. Stemming\n",
                "    3. Lemmitization\n",
                "    \n",
                "    '''\n",
                "    data.text=data.text.apply(lambda x: cleaning_stopwords(x)) #removing stopwords\n",
                "    # tokenizer=RegexpTokenizer(r'\\w+')\n",
                "    # data.text=data.text.apply(tokenizer.tokenize)\n",
                "    #data.text= data.text.apply(lambda x: stemming_on_text(x))\n",
                "    #data.text= data.text.apply(lambda x: lemmatizer_on_text(x))\n",
                "    return data\n",
                "\n",
                "\n",
                "\n",
                "#data['text2']= pre_processing_02(data)\n",
                "\n",
                "\n",
                "#Tokenizing"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 224,
            "source": [
                "#Removing stop words\n",
                "\n",
                "stopwords_list=set(stopwords.words('english'))\n",
                "def cleaning_stopwords(text):\n",
                "  return \" \".join([word for word in str(text).split() if word not in stopwords_list])\n",
                "df.text=df.text.apply(lambda x: cleaning_stopwords(x))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "source": [
                "# Stemming\n",
                "\n",
                "def stemming_on_text(data):\n",
                "    st=nltk.PorterStemmer()\n",
                "    text= [st.stem(word) for word in data]\n",
                "    return data\n",
                "data.text= data.text.apply(lambda x: stemming_on_text(x))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "source": [
                "#Lemmitization\n",
                "\n",
                "from nltk.stem import WordNetLemmatizer \n",
                "def lemmatizer_on_text(data):\n",
                "    wnl = WordNetLemmatizer()\n",
                "    text= [wnl.lemmatize(word) for word in data]\n",
                "    return data\n",
                "data.text= data.text.apply(lambda x: lemmatizer_on_text(x))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "source": [
                "all_text = ''.join([c for c in data.text])\n",
                "words_split = all_text.split(\" \")\n",
                "len(list(set(words_split)))\n",
                "#print ('Number of words :', len(words_split))"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "76089"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 146
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "source": [
                "# from collections import Counter\n",
                "# # Count all the words using Counter Method\n",
                "# count_words = Counter(words_split)\n",
                "\n",
                "# total_words = len(count_words)\n",
                "# sorted_words = count_words.most_common(50000)\n",
                "# keepwords= list(set([x[0] for x in sorted_words]))\n",
                "nltk.download('words')\n",
                "from nltk.corpus import words\n",
                "\n",
                "def keeping_common_words(text):\n",
                "    return \" \".join([word for word in str(text).split() if word in words.words()])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[nltk_data] Downloading package words to\n",
                        "[nltk_data]     /Users/sarwaridas/nltk_data...\n",
                        "[nltk_data]   Package words is already up-to-date!\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 148,
            "source": [
                "# data.text=data.text.apply(lambda x: keeping_common_words(x))\n",
                "# data.text.head()\n",
                "\n",
                "data.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(40000, 2)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 148
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "source": [
                "data.to_csv(\"CLEANED_FOR_REAL.csv\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "source": [
                "data.isna().sum()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "label    0\n",
                            "text     0\n",
                            "dtype: int64"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 151
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "source": [
                "os.getcwd()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'/Users/sarwaridas/Desktop/IDS 703/703-final-project/10_code'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 152
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.0",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.0 64-bit ('venv1': conda)"
        },
        "interpreter": {
            "hash": "7a6d299408f2023e0a200d93f96af30feb246c6cc222adc42d2612aa5ba88688"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}